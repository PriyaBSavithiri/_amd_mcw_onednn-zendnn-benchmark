From 3197d571cad64f7b93a67c223d26478d521f580c Mon Sep 17 00:00:00 2001
From: PriyaBSavithiri <priya.savithiri@multicorewareinc.com>
Date: Thu, 8 Jun 2023 13:57:23 +0530
Subject: [PATCH] Wavenet Changes TF-2

---
 generate.py             | 35 +++++++++-------
 test/test_generation.py | 12 +++---
 test/test_model.py      | 14 +++----
 train.py                | 24 +++++------
 wavenet/audio_reader.py |  8 ++--
 wavenet/model.py        | 92 ++++++++++++++++++++---------------------
 wavenet/ops.py          | 44 ++++++++++----------
 7 files changed, 116 insertions(+), 113 deletions(-)

diff --git a/generate.py b/generate.py
index 0a119ce..534750d 100644
--- a/generate.py
+++ b/generate.py
@@ -9,6 +9,7 @@ import os
 import librosa
 import numpy as np
 import tensorflow as tf
+tf.compat.v1.disable_eager_execution()
 #tracefile related
 from tensorflow.python.platform import gfile
 from tensorflow.python.client import timeline
@@ -145,15 +146,16 @@ def create_seed(filename,
     audio = audio_reader.trim_silence(audio, silence_threshold)
 
     quantized = mu_law_encode(audio, quantization_channels)
-    cut_index = tf.cond(tf.size(quantized) < tf.constant(window_size),
-                        lambda: tf.size(quantized),
-                        lambda: tf.constant(window_size))
+    cut_index = tf.cond(pred=tf.size(input=quantized) < tf.constant(window_size),
+                        true_fn=lambda: tf.size(input=quantized),
+                        false_fn=lambda: tf.constant(window_size))
 
     return quantized[:cut_index]
 
 
 def main():
     args = get_arguments()
+    batch_size = 1
     started_datestring = "{0:%Y-%m-%dT%H-%M-%S}".format(datetime.now())
     logdir = os.path.join(args.logdir, 'generate', started_datestring)
     with open(args.wavenet_params, 'r') as config_file:
@@ -162,22 +164,22 @@ def main():
     #tracefile related
     trace_filename = args.trace_file
     if trace_filename: 
-      run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
-      run_metadata = tf.RunMetadata()
+      run_options = tf.compat.v1.RunOptions(trace_level=tf.compat.v1.RunOptions.FULL_TRACE)
+      run_metadata = tf.compat.v1.RunMetadata()
     else:
       run_options = None 
       run_metadata = None 
 
-    session_config = tf.ConfigProto(allow_soft_placement=True)
+    session_config = tf.compat.v1.ConfigProto(allow_soft_placement=True)
     #inter and intra parallelism for CPU
     session_config.inter_op_parallelism_threads = args.num_inter_threads
     session_config.intra_op_parallelism_threads = args.num_intra_threads
     session_config.gpu_options.allow_growth = True
 
-    sess = tf.Session(config=session_config)
+    sess = tf.compat.v1.Session(config=session_config)
 
     net = WaveNetModel(
-        batch_size=1,
+        batch_size=batch_size,
         dilations=wavenet_params['dilations'],
         filter_width=wavenet_params['filter_width'],
         residual_channels=wavenet_params['residual_channels'],
@@ -190,7 +192,7 @@ def main():
         global_condition_channels=args.gc_channels,
         global_condition_cardinality=args.gc_cardinality)
 
-    samples = tf.placeholder(tf.int32)
+    samples = tf.compat.v1.placeholder(tf.int32)
 
     if args.fast_generation:
         next_sample = net.predict_proba_incremental(samples, args.gc_id)
@@ -198,13 +200,13 @@ def main():
         next_sample = net.predict_proba(samples, args.gc_id)
 
     if args.fast_generation:
-        sess.run(tf.global_variables_initializer())
+        sess.run(tf.compat.v1.global_variables_initializer())
         sess.run(net.init_ops)
 
     variables_to_restore = {
-        var.name[:-2]: var for var in tf.global_variables()
+        var.name[:-2]: var for var in tf.compat.v1.global_variables()
         if not ('state_buffer' in var.name or 'pointer' in var.name)}
-    saver = tf.train.Saver(variables_to_restore)
+    saver = tf.compat.v1.train.Saver(variables_to_restore)
 
     print('Restoring model from {}'.format(args.checkpoint))
     saver.restore(sess, args.checkpoint)
@@ -311,14 +313,15 @@ def main():
     print()
     if args.samples >500 : 
       total_time = current_time - start_time
-      print("Average Throughput of whole run: Samples / sec: %f" % (args.samples/total_time))
+      print("Batch Size: ", batch_size)
+      print("Average Throughput of whole run: Samples / sec: %f" % (args.samples * batch_size/total_time))
       print("Average Latency of whole run: msec / sample: %f" % (total_time/args.samples*1000))
 
     # Save the result as an audio summary.
     datestring = str(datetime.now()).replace(' ', 'T')
-    writer = tf.summary.FileWriter(logdir)
-    tf.summary.audio('generated', decode, wavenet_params['sample_rate'])
-    summaries = tf.summary.merge_all()
+    writer = tf.compat.v1.summary.FileWriter(logdir)
+    tf.compat.v1.summary.audio('generated', decode, wavenet_params['sample_rate'])
+    summaries = tf.compat.v1.summary.merge_all()
     summary_out = sess.run(summaries,
                            feed_dict={samples: np.reshape(waveform, [-1, 1])})
     writer.add_summary(summary_out)
diff --git a/test/test_generation.py b/test/test_generation.py
index 8189c81..333367b 100644
--- a/test/test_generation.py
+++ b/test/test_generation.py
@@ -19,13 +19,13 @@ class TestGeneration(tf.test.TestCase):
     def testGenerateSimple(self):
         '''Generate a few samples using the naive method and
         perform sanity checks on the output.'''
-        waveform = tf.placeholder(tf.int32)
+        waveform = tf.compat.v1.placeholder(tf.int32)
         np.random.seed(0)
         data = np.random.randint(128, size=1000)
         proba = self.net.predict_proba(waveform)
 
         with self.test_session() as sess:
-            sess.run(tf.global_variables_initializer())
+            sess.run(tf.compat.v1.global_variables_initializer())
             proba = sess.run(proba, feed_dict={waveform: data})
 
         self.assertAllEqual(proba.shape, [128])
@@ -34,13 +34,13 @@ class TestGeneration(tf.test.TestCase):
     def testGenerateFast(self):
         '''Generate a few samples using the fast method and
         perform sanity checks on the output.'''
-        waveform = tf.placeholder(tf.int32)
+        waveform = tf.compat.v1.placeholder(tf.int32)
         np.random.seed(0)
         data = np.random.randint(128)
         proba = self.net.predict_proba_incremental(waveform)
 
         with self.test_session() as sess:
-            sess.run(tf.global_variables_initializer())
+            sess.run(tf.compat.v1.global_variables_initializer())
             sess.run(self.net.init_ops)
             proba = sess.run(proba, feed_dict={waveform: data})
 
@@ -48,13 +48,13 @@ class TestGeneration(tf.test.TestCase):
         self.assertTrue(np.all((proba >= 0) & (proba <= (128 - 1))))
 
     def testCompareSimpleFast(self):
-        waveform = tf.placeholder(tf.int32)
+        waveform = tf.compat.v1.placeholder(tf.int32)
         np.random.seed(0)
         data = np.random.randint(128, size=1000)
         proba = self.net.predict_proba(waveform)
         proba_fast = self.net.predict_proba_incremental(waveform)
         with self.test_session() as sess:
-            sess.run(tf.global_variables_initializer())
+            sess.run(tf.compat.v1.global_variables_initializer())
             sess.run(self.net.init_ops)
             # Prime the incremental generation with all samples
             # except the last one
diff --git a/test/test_model.py b/test/test_model.py
index 3182af9..db50d9f 100644
--- a/test/test_model.py
+++ b/test/test_model.py
@@ -93,8 +93,8 @@ def generate_waveform(sess, net, fast_generation, gc, samples_placeholder,
 
 
 def generate_waveforms(sess, net, fast_generation, global_condition):
-    samples_placeholder = tf.placeholder(tf.int32)
-    gc_placeholder = tf.placeholder(tf.int32) if global_condition is not None \
+    samples_placeholder = tf.compat.v1.placeholder(tf.int32)
+    gc_placeholder = tf.compat.v1.placeholder(tf.int32) if global_condition is not None \
         else None
 
     net.batch_size = 1
@@ -193,7 +193,7 @@ class TestNet(tf.test.TestCase):
                                 global_condition_cardinality=None)
 
     def _save_net(sess):
-        saver = tf.train.Saver(var_list=tf.trainable_variables())
+        saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.trainable_variables())
         saver.save(sess, os.path.join('tmp', 'test.ckpt'))
 
     # Train a net on a short clip of 3 sine waves superimposed
@@ -228,17 +228,17 @@ class TestNet(tf.test.TestCase):
             audio = np.pad(audio, (self.net.receptive_field - 1, 0),
                            'constant')
 
-        audio_placeholder = tf.placeholder(dtype=tf.float32)
-        gc_placeholder = tf.placeholder(dtype=tf.int32)  \
+        audio_placeholder = tf.compat.v1.placeholder(dtype=tf.float32)
+        gc_placeholder = tf.compat.v1.placeholder(dtype=tf.int32)  \
             if self.global_conditioning else None
 
         loss = self.net.loss(input_batch=audio_placeholder,
                              global_condition_batch=gc_placeholder)
         optimizer = optimizer_factory[self.optimizer_type](
                       learning_rate=self.learning_rate, momentum=self.momentum)
-        trainable = tf.trainable_variables()
+        trainable = tf.compat.v1.trainable_variables()
         optim = optimizer.minimize(loss, var_list=trainable)
-        init = tf.global_variables_initializer()
+        init = tf.compat.v1.global_variables_initializer()
 
         generated_waveform = None
         max_allowed_loss = 0.1
diff --git a/train.py b/train.py
index 02ec800..6721a65 100644
--- a/train.py
+++ b/train.py
@@ -209,7 +209,7 @@ def main():
     coord = tf.train.Coordinator()
 
     # Load raw waveform from VCTK corpus.
-    with tf.name_scope('create_inputs'):
+    with tf.compat.v1.name_scope('create_inputs'):
         # Allow silence trimming to be skipped by specifying a threshold near
         # zero.
         silence_threshold = args.silence_threshold if args.silence_threshold > \
@@ -256,22 +256,22 @@ def main():
     optimizer = optimizer_factory[args.optimizer](
                     learning_rate=args.learning_rate,
                     momentum=args.momentum)
-    trainable = tf.trainable_variables()
+    trainable = tf.compat.v1.trainable_variables()
     optim = optimizer.minimize(loss, var_list=trainable)
 
     # Set up logging for TensorBoard.
-    writer = tf.summary.FileWriter(logdir)
-    writer.add_graph(tf.get_default_graph())
-    run_metadata = tf.RunMetadata()
-    summaries = tf.summary.merge_all()
+    writer = tf.compat.v1.summary.FileWriter(logdir)
+    writer.add_graph(tf.compat.v1.get_default_graph())
+    run_metadata = tf.compat.v1.RunMetadata()
+    summaries = tf.compat.v1.summary.merge_all()
 
     # Set up session
-    sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))
-    init = tf.global_variables_initializer()
+    sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=False))
+    init = tf.compat.v1.global_variables_initializer()
     sess.run(init)
 
     # Saver for storing checkpoints of the model.
-    saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)
+    saver = tf.compat.v1.train.Saver(var_list=tf.compat.v1.trainable_variables(), max_to_keep=args.max_checkpoints)
 
     try:
         saved_global_step = load(saver, sess, restore_from)
@@ -286,7 +286,7 @@ def main():
               "the previous model.")
         raise
 
-    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
+    threads = tf.compat.v1.train.start_queue_runners(sess=sess, coord=coord)
     reader.start_threads(sess)
 
     step = None
@@ -297,8 +297,8 @@ def main():
             if args.store_metadata and step % 50 == 0:
                 # Slow run that stores extra information for debugging.
                 print('Storing metadata')
-                run_options = tf.RunOptions(
-                    trace_level=tf.RunOptions.FULL_TRACE)
+                run_options = tf.compat.v1.RunOptions(
+                    trace_level=tf.compat.v1.RunOptions.FULL_TRACE)
                 summary, loss_value, _ = sess.run(
                     [summaries, loss, optim],
                     options=run_options,
diff --git a/wavenet/audio_reader.py b/wavenet/audio_reader.py
index a65e9c8..b53419c 100644
--- a/wavenet/audio_reader.py
+++ b/wavenet/audio_reader.py
@@ -105,15 +105,15 @@ class AudioReader(object):
         self.silence_threshold = silence_threshold
         self.gc_enabled = gc_enabled
         self.threads = []
-        self.sample_placeholder = tf.placeholder(dtype=tf.float32, shape=None)
-        self.queue = tf.PaddingFIFOQueue(queue_size,
+        self.sample_placeholder = tf.compat.v1.placeholder(dtype=tf.float32, shape=None)
+        self.queue = tf.queue.PaddingFIFOQueue(queue_size,
                                          ['float32'],
                                          shapes=[(None, 1)])
         self.enqueue = self.queue.enqueue([self.sample_placeholder])
 
         if self.gc_enabled:
-            self.id_placeholder = tf.placeholder(dtype=tf.int32, shape=())
-            self.gc_queue = tf.PaddingFIFOQueue(queue_size, ['int32'],
+            self.id_placeholder = tf.compat.v1.placeholder(dtype=tf.int32, shape=())
+            self.gc_queue = tf.queue.PaddingFIFOQueue(queue_size, ['int32'],
                                                 shapes=[()])
             self.gc_enqueue = self.gc_queue.enqueue([self.id_placeholder])
 
diff --git a/wavenet/model.py b/wavenet/model.py
index d2e79a9..5d172cb 100644
--- a/wavenet/model.py
+++ b/wavenet/model.py
@@ -7,7 +7,7 @@ from .ops import causal_conv, mu_law_encode
 def create_variable(name, shape):
     '''Create a convolution filter variable with the specified name and shape,
     and initialize it using Xavier initialition.'''
-    initializer = tf.contrib.layers.xavier_initializer_conv2d()
+    initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=1.0, mode="fan_avg", distribution="uniform")
     variable = tf.Variable(initializer(shape=shape), name=name)
     return variable
 
@@ -24,7 +24,7 @@ def create_embedding_table(name, shape):
 def create_bias_variable(name, shape):
     '''Create a bias variable with the specified name and shape and initialize
     it to zero.'''
-    initializer = tf.constant_initializer(value=0.0, dtype=tf.float32)
+    initializer = tf.compat.v1.constant_initializer(value=0.0, dtype=tf.float32)
     return tf.Variable(initializer(shape=shape), name)
 
 
@@ -131,7 +131,7 @@ class WaveNetModel(object):
 
         var = dict()
 
-        with tf.variable_scope('wavenet'):
+        with tf.compat.v1.variable_scope('wavenet'):
             if self.global_condition_cardinality is not None:
                 # We only look up the embedding if we are conditioning on a
                 # set of mutually-exclusive categories. We can also condition
@@ -139,7 +139,7 @@ class WaveNetModel(object):
                 # given to us and we don't need to do the embedding lookup.
                 # Still another alternative is no global condition at all, in
                 # which case we also don't do a tf.nn.embedding_lookup.
-                with tf.variable_scope('embeddings'):
+                with tf.compat.v1.variable_scope('embeddings'):
                     layer = dict()
                     layer['gc_embedding'] = create_embedding_table(
                         'gc_embedding',
@@ -147,7 +147,7 @@ class WaveNetModel(object):
                          self.global_condition_channels])
                     var['embeddings'] = layer
 
-            with tf.variable_scope('causal_layer'):
+            with tf.compat.v1.variable_scope('causal_layer'):
                 layer = dict()
                 if self.scalar_input:
                     initial_channels = 1
@@ -163,9 +163,9 @@ class WaveNetModel(object):
                 var['causal_layer'] = layer
 
             var['dilated_stack'] = list()
-            with tf.variable_scope('dilated_stack'):
+            with tf.compat.v1.variable_scope('dilated_stack'):
                 for i, dilation in enumerate(self.dilations):
-                    with tf.variable_scope('layer{}'.format(i)):
+                    with tf.compat.v1.variable_scope('layer{}'.format(i)):
                         current = dict()
                         current['filter'] = create_variable(
                             'filter',
@@ -214,7 +214,7 @@ class WaveNetModel(object):
 
                         var['dilated_stack'].append(current)
 
-            with tf.variable_scope('postprocessing'):
+            with tf.compat.v1.variable_scope('postprocessing'):
                 current = dict()
                 current['postprocess1'] = create_variable(
                     'postprocess1',
@@ -238,7 +238,7 @@ class WaveNetModel(object):
 
         The layer can change the number of channels.
         '''
-        with tf.name_scope('causal_layer'):
+        with tf.compat.v1.name_scope('causal_layer'):
             weights_filter = self.variables['causal_layer']['filter']
             return causal_conv(input_batch, weights_filter, 1)
 
@@ -280,14 +280,14 @@ class WaveNetModel(object):
 
         if global_condition_batch is not None:
             weights_gc_filter = variables['gc_filtweights']
-            conv_filter = conv_filter + tf.nn.conv1d(global_condition_batch,
-                                                     weights_gc_filter,
+            conv_filter = conv_filter + tf.nn.conv1d(input=global_condition_batch,
+                                                     filters=weights_gc_filter,
                                                      stride=1,
                                                      padding="SAME",
                                                      name="gc_filter")
             weights_gc_gate = variables['gc_gateweights']
-            conv_gate = conv_gate + tf.nn.conv1d(global_condition_batch,
-                                                 weights_gc_gate,
+            conv_gate = conv_gate + tf.nn.conv1d(input=global_condition_batch,
+                                                 filters=weights_gc_gate,
                                                  stride=1,
                                                  padding="SAME",
                                                  name="gc_gate")
@@ -303,14 +303,14 @@ class WaveNetModel(object):
         # The 1x1 conv to produce the residual output
         weights_dense = variables['dense']
         transformed = tf.nn.conv1d(
-            out, weights_dense, stride=1, padding="SAME", name="dense")
+            input=out, filters=weights_dense, stride=1, padding="SAME", name="dense")
 
         # The 1x1 conv to produce the skip output
-        skip_cut = tf.shape(out)[1] - output_width
+        skip_cut = tf.shape(input=out)[1] - output_width
         out_skip = tf.slice(out, [0, skip_cut, 0], [-1, -1, -1])
         weights_skip = variables['skip']
         skip_contribution = tf.nn.conv1d(
-            out_skip, weights_skip, stride=1, padding="SAME", name="skip")
+            input=out_skip, filters=weights_skip, stride=1, padding="SAME", name="skip")
 
         if self.use_biases:
             dense_bias = variables['dense_bias']
@@ -330,7 +330,7 @@ class WaveNetModel(object):
                 tf.histogram_summary(layer + '_biases_dense', dense_bias)
                 tf.histogram_summary(layer + '_biases_skip', skip_bias)
 
-        input_cut = tf.shape(input_batch)[1] - tf.shape(transformed)[1]
+        input_cut = tf.shape(input=input_batch)[1] - tf.shape(input=transformed)[1]
         input_batch = tf.slice(input_batch, [0, input_cut, 0], [-1, -1, -1])
 
         return skip_contribution, input_batch + transformed
@@ -345,7 +345,7 @@ class WaveNetModel(object):
         return output
 
     def _generator_causal_layer(self, input_batch, state_batch):
-        with tf.name_scope('causal_layer'):
+        with tf.compat.v1.name_scope('causal_layer'):
             weights_filter = self.variables['causal_layer']['filter']
             output = self._generator_conv(
                 input_batch, state_batch, weights_filter)
@@ -400,18 +400,18 @@ class WaveNetModel(object):
         # Pre-process the input with a regular convolution
         current_layer = self._create_causal_layer(current_layer)
 
-        output_width = tf.shape(input_batch)[1] - self.receptive_field + 1
+        output_width = tf.shape(input=input_batch)[1] - self.receptive_field + 1
 
         # Add all defined dilation layers.
-        with tf.name_scope('dilated_stack'):
+        with tf.compat.v1.name_scope('dilated_stack'):
             for layer_index, dilation in enumerate(self.dilations):
-                with tf.name_scope('layer{}'.format(layer_index)):
+                with tf.compat.v1.name_scope('layer{}'.format(layer_index)):
                     output, current_layer = self._create_dilation_layer(
                         current_layer, layer_index, dilation,
                         global_condition_batch, output_width)
                     outputs.append(output)
 
-        with tf.name_scope('postprocessing'):
+        with tf.compat.v1.name_scope('postprocessing'):
             # Perform (+) -> ReLU -> 1x1 conv -> ReLU -> 1x1 conv to
             # postprocess the output.
             w1 = self.variables['postprocessing']['postprocess1']
@@ -431,11 +431,11 @@ class WaveNetModel(object):
             # all up here.
             total = sum(outputs)
             transformed1 = tf.nn.relu(total)
-            conv1 = tf.nn.conv1d(transformed1, w1, stride=1, padding="SAME")
+            conv1 = tf.nn.conv1d(input=transformed1, filters=w1, stride=1, padding="SAME")
             if self.use_biases:
                 conv1 = tf.add(conv1, b1)
             transformed2 = tf.nn.relu(conv1)
-            conv2 = tf.nn.conv1d(transformed2, w2, stride=1, padding="SAME")
+            conv2 = tf.nn.conv1d(input=transformed2, filters=w2, stride=1, padding="SAME")
             if self.use_biases:
                 conv2 = tf.add(conv2, b2)
 
@@ -448,7 +448,7 @@ class WaveNetModel(object):
         outputs = []
         current_layer = input_batch
 
-        q = tf.FIFOQueue(
+        q = tf.queue.FIFOQueue(
             1,
             dtypes=tf.float32,
             shapes=(self.batch_size, self.quantization_channels))
@@ -464,11 +464,11 @@ class WaveNetModel(object):
                             current_layer, current_state)
 
         # Add all defined dilation layers.
-        with tf.name_scope('dilated_stack'):
+        with tf.compat.v1.name_scope('dilated_stack'):
             for layer_index, dilation in enumerate(self.dilations):
-                with tf.name_scope('layer{}'.format(layer_index)):
+                with tf.compat.v1.name_scope('layer{}'.format(layer_index)):
 
-                    q = tf.FIFOQueue(
+                    q = tf.queue.FIFOQueue(
                         dilation,
                         dtypes=tf.float32,
                         shapes=(self.batch_size, self.residual_channels))
@@ -488,7 +488,7 @@ class WaveNetModel(object):
         self.init_ops = init_ops
         self.push_ops = push_ops
 
-        with tf.name_scope('postprocessing'):
+        with tf.compat.v1.name_scope('postprocessing'):
             variables = self.variables['postprocessing']
             # Perform (+) -> ReLU -> 1x1 conv -> ReLU -> 1x1 conv to
             # postprocess the output.
@@ -519,7 +519,7 @@ class WaveNetModel(object):
         This allows the definition of the network as a categorical distribution
         over a finite set of possible amplitudes.
         '''
-        with tf.name_scope('one_hot_encode'):
+        with tf.compat.v1.name_scope('one_hot_encode'):
             encoded = tf.one_hot(
                 input_batch,
                 depth=self.quantization_channels,
@@ -540,8 +540,8 @@ class WaveNetModel(object):
             # Only lookup the embedding if the global condition is presented
             # as an integer of mutually-exclusive categories ...
             embedding_table = self.variables['embeddings']['gc_embedding']
-            embedding = tf.nn.embedding_lookup(embedding_table,
-                                               global_condition)
+            embedding = tf.nn.embedding_lookup(params=embedding_table,
+                                               ids=global_condition)
         elif global_condition is not None:
             # ... else the global_condition (if any) is already provided
             # as an embedding.
@@ -570,7 +570,7 @@ class WaveNetModel(object):
         all samples in the input waveform.
         If you want to generate audio by feeding the output of the network back
         as an input, see predict_proba_incremental for a faster alternative.'''
-        with tf.name_scope(name):
+        with tf.compat.v1.name_scope(name):
             if self.scalar_input:
                 encoded = tf.cast(waveform, tf.float32)
                 encoded = tf.reshape(encoded, [-1, 1])
@@ -585,7 +585,7 @@ class WaveNetModel(object):
                 tf.nn.softmax(tf.cast(out, tf.float64)), tf.float32)
             last = tf.slice(
                 proba,
-                [tf.shape(proba)[0] - 1, 0],
+                [tf.shape(input=proba)[0] - 1, 0],
                 [1, self.quantization_channels])
             return tf.reshape(last, [-1])
 
@@ -600,17 +600,17 @@ class WaveNetModel(object):
         if self.scalar_input:
             raise NotImplementedError("Incremental generation does not "
                                       "support scalar input yet.")
-        with tf.name_scope(name):
+        with tf.compat.v1.name_scope(name):
             encoded = tf.one_hot(waveform, self.quantization_channels)
             encoded = tf.reshape(encoded, [-1, self.quantization_channels])
             gc_embedding = self._embed_gc(global_condition)
             raw_output = self._create_generator(encoded, gc_embedding)
             out = tf.reshape(raw_output, [-1, self.quantization_channels])
             proba = tf.cast(
-                tf.nn.softmax(tf.cast(out, tf.float64)), tf.float32)
+                tf.nn.softmax(tf.cast(out, tf.float32)), tf.float32)
             last = tf.slice(
                 proba,
-                [tf.shape(proba)[0] - 1, 0],
+                [tf.shape(input=proba)[0] - 1, 0],
                 [1, self.quantization_channels])
             return tf.reshape(last, [-1])
 
@@ -623,7 +623,7 @@ class WaveNetModel(object):
 
         The variables are all scoped to the given name.
         '''
-        with tf.name_scope(name):
+        with tf.compat.v1.name_scope(name):
             # We mu-law encode and quantize the input audioform.
             encoded_input = mu_law_encode(input_batch,
                                           self.quantization_channels)
@@ -638,13 +638,13 @@ class WaveNetModel(object):
                 network_input = encoded
 
             # Cut off the last sample of network input to preserve causality.
-            network_input_width = tf.shape(network_input)[1] - 1
+            network_input_width = tf.shape(input=network_input)[1] - 1
             network_input = tf.slice(network_input, [0, 0, 0],
                                      [-1, network_input_width, -1])
 
             raw_output = self._create_network(network_input, gc_embedding)
 
-            with tf.name_scope('loss'):
+            with tf.compat.v1.name_scope('loss'):
                 # Cut off the samples corresponding to the receptive field
                 # for the first predicted sample.
                 target_output = tf.slice(
@@ -659,24 +659,24 @@ class WaveNetModel(object):
                                         [-1, self.quantization_channels])
                 loss = tf.nn.softmax_cross_entropy_with_logits(
                     logits=prediction,
-                    labels=target_output)
-                reduced_loss = tf.reduce_mean(loss)
+                    labels=tf.stop_gradient(target_output))
+                reduced_loss = tf.reduce_mean(input_tensor=loss)
 
-                tf.summary.scalar('loss', reduced_loss)
+                tf.compat.v1.summary.scalar('loss', reduced_loss)
 
                 if l2_regularization_strength is None:
                     return reduced_loss
                 else:
                     # L2 regularization for all trainable parameters
                     l2_loss = tf.add_n([tf.nn.l2_loss(v)
-                                        for v in tf.trainable_variables()
+                                        for v in tf.compat.v1.trainable_variables()
                                         if not('bias' in v.name)])
 
                     # Add the regularization term to the loss
                     total_loss = (reduced_loss +
                                   l2_regularization_strength * l2_loss)
 
-                    tf.summary.scalar('l2_loss', l2_loss)
-                    tf.summary.scalar('total_loss', total_loss)
+                    tf.compat.v1.summary.scalar('l2_loss', l2_loss)
+                    tf.compat.v1.summary.scalar('total_loss', total_loss)
 
                     return total_loss
diff --git a/wavenet/ops.py b/wavenet/ops.py
index 304791b..22dc030 100644
--- a/wavenet/ops.py
+++ b/wavenet/ops.py
@@ -4,17 +4,17 @@ import tensorflow as tf
 
 
 def create_adam_optimizer(learning_rate, momentum):
-    return tf.train.AdamOptimizer(learning_rate=learning_rate,
+    return tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate,
                                   epsilon=1e-4)
 
 
 def create_sgd_optimizer(learning_rate, momentum):
-    return tf.train.MomentumOptimizer(learning_rate=learning_rate,
+    return tf.compat.v1.train.MomentumOptimizer(learning_rate=learning_rate,
                                       momentum=momentum)
 
 
 def create_rmsprop_optimizer(learning_rate, momentum):
-    return tf.train.RMSPropOptimizer(learning_rate=learning_rate,
+    return tf.compat.v1.train.RMSPropOptimizer(learning_rate=learning_rate,
                                      momentum=momentum,
                                      epsilon=1e-5)
 
@@ -25,36 +25,36 @@ optimizer_factory = {'adam': create_adam_optimizer,
 
 
 def time_to_batch(value, dilation, name=None):
-    with tf.name_scope('time_to_batch'):
-        shape = tf.shape(value)
+    with tf.compat.v1.name_scope('time_to_batch'):
+        shape = tf.shape(input=value)
         pad_elements = dilation - 1 - (shape[1] + dilation - 1) % dilation
-        padded = tf.pad(value, [[0, 0], [0, pad_elements], [0, 0]])
+        padded = tf.pad(tensor=value, paddings=[[0, 0], [0, pad_elements], [0, 0]])
         reshaped = tf.reshape(padded, [-1, dilation, shape[2]])
-        transposed = tf.transpose(reshaped, perm=[1, 0, 2])
+        transposed = tf.transpose(a=reshaped, perm=[1, 0, 2])
         return tf.reshape(transposed, [shape[0] * dilation, -1, shape[2]])
 
 
 def batch_to_time(value, dilation, name=None):
-    with tf.name_scope('batch_to_time'):
-        shape = tf.shape(value)
+    with tf.compat.v1.name_scope('batch_to_time'):
+        shape = tf.shape(input=value)
         prepared = tf.reshape(value, [dilation, -1, shape[2]])
-        transposed = tf.transpose(prepared, perm=[1, 0, 2])
+        transposed = tf.transpose(a=prepared, perm=[1, 0, 2])
         return tf.reshape(transposed,
-                          [tf.div(shape[0], dilation), -1, shape[2]])
+                          [tf.compat.v1.div(shape[0], dilation), -1, shape[2]])
 
 
 def causal_conv(value, filter_, dilation, name='causal_conv'):
-    with tf.name_scope(name):
-        filter_width = tf.shape(filter_)[0]
+    with tf.compat.v1.name_scope(name):
+        filter_width = tf.shape(input=filter_)[0]
         if dilation > 1:
             transformed = time_to_batch(value, dilation)
-            conv = tf.nn.conv1d(transformed, filter_, stride=1,
+            conv = tf.nn.conv1d(input=transformed, filters=filter_, stride=1,
                                 padding='VALID')
             restored = batch_to_time(conv, dilation)
         else:
-            restored = tf.nn.conv1d(value, filter_, stride=1, padding='VALID')
+            restored = tf.nn.conv1d(input=value, filters=filter_, stride=1, padding='VALID')
         # Remove excess elements at the end.
-        out_width = tf.shape(value)[1] - (filter_width - 1) * dilation
+        out_width = tf.shape(input=value)[1] - (filter_width - 1) * dilation
         result = tf.slice(restored,
                           [0, 0, 0],
                           [-1, out_width, -1])
@@ -63,24 +63,24 @@ def causal_conv(value, filter_, dilation, name='causal_conv'):
 
 def mu_law_encode(audio, quantization_channels):
     '''Quantizes waveform amplitudes.'''
-    with tf.name_scope('encode'):
-        mu = tf.to_float(quantization_channels - 1)
+    with tf.compat.v1.name_scope('encode'):
+        mu = tf.cast(quantization_channels - 1, dtype=tf.float32)
         # Perform mu-law companding transformation (ITU-T, 1988).
         # Minimum operation is here to deal with rare large amplitudes caused
         # by resampling.
         safe_audio_abs = tf.minimum(tf.abs(audio), 1.0)
-        magnitude = tf.log1p(mu * safe_audio_abs) / tf.log1p(mu)
+        magnitude = tf.math.log1p(mu * safe_audio_abs) / tf.math.log1p(mu)
         signal = tf.sign(audio) * magnitude
         # Quantize signal to the specified number of levels.
-        return tf.to_int32((signal + 1) / 2 * mu + 0.5)
+        return tf.cast((signal + 1) / 2 * mu + 0.5, dtype=tf.int32)
 
 
 def mu_law_decode(output, quantization_channels):
     '''Recovers waveform from quantized values.'''
-    with tf.name_scope('decode'):
+    with tf.compat.v1.name_scope('decode'):
         mu = quantization_channels - 1
         # Map values back to [-1, 1].
-        signal = 2 * (tf.to_float(output) / mu) - 1
+        signal = 2 * (tf.cast(output, dtype=tf.float32) / mu) - 1
         # Perform inverse of mu-law transformation.
         magnitude = (1 / mu) * ((1 + mu)**abs(signal) - 1)
         return tf.sign(signal) * magnitude
-- 
2.17.1

